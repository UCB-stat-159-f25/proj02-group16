{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5425102-8284-45dc-8adf-eccb8e5a020b",
   "metadata": {},
   "source": [
    "# Part 4: Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489902ba-29e8-4335-b055-150e6ae0461b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 4: Choose your own advecnture! (7 Points; Optional for Extra Credit)\n",
    "\n",
    "This section is open ended and your chance to explare any advanced analysis. Please perform any additional analysis you find interesting! Suggested analyses (only do one max):\n",
    "\n",
    "- Topic evolution over time - see https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#visualization \n",
    "- Word frequency over time - does the frequency of certain words change over time\n",
    "- Semantic similarity - investigate similarity within and between presidents or time periods. For example, similarity between one presidents speeches, e.g. are all of Biden's speeches similar to each other? How similar are they to Trump's speeches? Are speeches from the 2000s more similar to each other than speeches in the 1800s? Which two presidents have the most similar speeches? See https://spacy.io/usage/linguistic-features#vectors-similarity \n",
    "-  Named Entity Recognition - which entity types are most common in speeches? What are the most common words for each entity type - see https://spacy.io/usage/linguistic-features#named-entities \n",
    "- Classification - can you build a classifier to detect democratic versus republican state of the union speeches from 1980-2024 - see https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af8b32-f072-4f95-b18f-0de7a3bb1891",
   "metadata": {},
   "source": [
    "## Word Frequency Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ccbf6c-b7e9-465d-afd1-dfd2cdc1b662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President</th>\n",
       "      <th>Year</th>\n",
       "      <th>Text</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2024</td>\n",
       "      <td>\\n[Before speaking, the President presented hi...</td>\n",
       "      <td>8003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2023</td>\n",
       "      <td>\\nThe President. Mr. Speaker——\\n[At this point...</td>\n",
       "      <td>8978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2022</td>\n",
       "      <td>\\nThe President. Thank you all very, very much...</td>\n",
       "      <td>7539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2021</td>\n",
       "      <td>\\nThe President. Thank you. Thank you. Thank y...</td>\n",
       "      <td>7734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020</td>\n",
       "      <td>\\nThe President. Thank you very much. Thank yo...</td>\n",
       "      <td>6169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         President  Year                                               Text  \\\n",
       "0  Joseph R. Biden  2024  \\n[Before speaking, the President presented hi...   \n",
       "1  Joseph R. Biden  2023  \\nThe President. Mr. Speaker——\\n[At this point...   \n",
       "2  Joseph R. Biden  2022  \\nThe President. Thank you all very, very much...   \n",
       "3  Joseph R. Biden  2021  \\nThe President. Thank you. Thank you. Thank y...   \n",
       "4  Donald J. Trump  2020  \\nThe President. Thank you very much. Thank yo...   \n",
       "\n",
       "   Word Count  \n",
       "0        8003  \n",
       "1        8978  \n",
       "2        7539  \n",
       "3        7734  \n",
       "4        6169  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import spacy\n",
    "\n",
    "plt.style.use('seaborn-v0_8-dark')\n",
    "sou = pd.read_csv(\"data/SOTU.csv\")\n",
    "sou[\"Year\"] = sou[\"Year\"].astype(int)\n",
    "sou.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79694d7-01cf-431d-8733-5665a5bf56e6",
   "metadata": {},
   "source": [
    "## Analyze each speech once, then aggregate lemma frequencies by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8cb67e-11be-4c37-b815-69000a43d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Dictionaries to store lemma frequencies and total token count per year\n",
    "year_lemma_counts = defaultdict(Counter)\n",
    "year_total_tokens = defaultdict(int)\n",
    "\n",
    "# Process each speech in the dataset\n",
    "for _, row in sou.iterrows():\n",
    "    year = int(row[\"Year\"])\n",
    "    text = row[\"Text\"]\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct or token.is_space:\n",
    "            continue\n",
    "        lemma = token.lemma_.lower()\n",
    "        year_lemma_counts[year][lemma] += 1\n",
    "        year_total_tokens[year] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06aface-a29f-4854-931a-0bcfeb1184eb",
   "metadata": {},
   "source": [
    "## Construct a Table of Relative Frequency Changes Over Time for Target Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068fb73-cbd8-4ddb-9254-137073443e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lemmas = [\"war\", \"job\", \"people\"]\n",
    "\n",
    "# Build a table of lemma counts and relative frequencies by year\n",
    "rows = []\n",
    "for year, lemma_counter in year_lemma_counts.items():\n",
    "    total = year_total_tokens[year]\n",
    "    if total == 0:\n",
    "        continue\n",
    "    for lemma in target_lemmas:\n",
    "        count = lemma_counter.get(lemma, 0)\n",
    "        rel_freq = count / total\n",
    "        rows.append({\"Year\": year, \"Lemma\": lemma, \"Count\": count, \"Relative_Frequency\": rel_freq})\n",
    "\n",
    "freq_df = pd.DataFrame(rows)\n",
    "\n",
    "freq_df = freq_df.sort_values([\"Lemma\", \"Year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4164eb87-4509-4fac-97f3-9d079c2d2906",
   "metadata": {},
   "source": [
    "## Plot the frequency changes of words over the entire time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2992b34-18af-4b28-b9d4-979004a03e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(\n",
    "    data=freq_df,\n",
    "    x=\"Year\",\n",
    "    y=\"Relative_Frequency\",\n",
    "    hue=\"Lemma\",\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "plt.title(\"Relative Frequency of Selected Lemmas in State of the Union Speeches (1790–2024)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Relative Frequency\")\n",
    "plt.legend(title=\"Lemma\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"outputs/word_frequency_over_time_full.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sotu)",
   "language": "python",
   "name": "sotu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
